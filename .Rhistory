model4 <- lm(data=boilwater, Time~Burner+Pot+Lid+Burner:Pot)
anova(model4)
hist(residuals(model4))
mean(Time[Pot=="Large"])+c(-1,1)*qt(0.975, df=26)*sqrt(SigHatSq)/12
mean(Time[Pot=="Medium"])+c(-1,1)*qt(0.975, df=26)*sqrt(SigHatSq)/12
mean(Time[Pot=="Small"])+c(-1,1)*qt(0.975, df=26)*sqrt(SigHatSq)/12
mean(Time[Pot=="Large",Burner=="Small"])+c(-1,1)*qt(0.975, df=26)*sqrt(SigHatSq)/12
mean(Time[Pot=="Large", Burner=="Small"])+c(-1,1)*qt(0.975, df=26)*sqrt(SigHatSq)/12
mean(Time[Pot=="Large"[Burner=="Small"])+c(-1,1)*qt(0.975, df=26)*sqrt(SigHatSq)/12
mean(Time[Pot=="Large"[Burner=="Small"]])+c(-1,1)*qt(0.975, df=26)*sqrt(SigHatSq)/12
#CHECKING FOR EXPECTED SAMPLE SIZE AND POWER
#A variance of 15^2 was assumed, given that almost all of the observations were expected to fall within a minute and a half of each other, and since 99.7% of the data falls within three standard deviations on either side of the mean, this gave us an expected standard deviation of 15.
ns<- 2:50
Boil <- power.anova.test(groups=12, between.var=var(c(30,30,30,30,30,30,0,0,0,0,0,0)), within.var=15^2,
sig.level=0.05, n=ns)
names(Boil)
Boil$power
plot(sample_size,powers,type="l",ylim=c(0,1)) #this shows what power each sample size n will give. The first one over 80% was chosen, which was 3.
tapply(Time,Pot,mean)
tapply(Time,Pot,sd)
tapply(Time,Pot,mean)
tapply(residuals(model))
interval(Time~Pot)
interaction.plot(Pot, Lid, Time, main="Interaction for Pot Size and Lid Presence")
interaction.plot(Burner, Lid, Time, main="Interaction for Burner Size and Lid Presence")
hist(residuals(model.no_3way),main=Histrogram of Residuals (no Three way interaction))
hist(residuals(model.no_3way),main="Histrogram of Residuals (no Three way interaction)")
#this histogram is nonnormal, so normality without three-way interaction will be checked
#Checking for normality of residuals without 3-way interaction
model.no_3way <- lm(data=boilwater, Time~Burner+Pot+Lid+Burner:Pot+Burner:Lid+Lid:Pot)
residuals(model.no_3way)
hist(residuals(model.no_3way),main="Histrogram of Residuals (no Three way interaction)")
hist(residuals(model.no_3way),main="Histrogram of Residuals (no 3way interaction)")
hist(residuals(model.no_3way),main="Residuals Histogram (no 3way interaction)")
hist(residuals(model.no_3way),main="Residuals Histogram (no three-way interaction)")
hist(residuals(model.no_3way),main="Residuals Histogram without three-way interaction")
hist(residuals(model.no_3way),main="Residuals Without three-way interaction")
hist(residuals(model.3way),main="Residuals With Three-way Interaction in model")
#Checking for normality of residuals with 3-way interaction
model.3way <- lm(data=boilwater, Time~Burner+Pot+Lid+Burner:Pot+Burner:Lid+Lid:Pot+Burner:Pot:Lid)
residuals(model.3way)
hist(residuals(model.3way),main="Residuals With Three-way Interaction in model")
hist(residuals(model.3way),main="Residuals With Three-way Interaction in Model")
hist(residuals(model.no_3way),main="Residuals Without Three-way Interaction in Model")
interaction.plot(Pot, Lid, Time, main="Interaction for Pot Size and Lid Presence")
interaction.plot(Burner, Lid, Time, main="Interaction for Burner Size and Lid Presence")
names(Boil)
Boil$power
plot(sample_size,powers,type="l",ylim=c(0,1)) #this shows what power each sample size n will give. The first one over 80% was chosen, which was 3.
plot(sample_size,Boil,type="l",ylim=c(0,1)) #this shows what power each sample size n will give. The first one over 80% was chosen, which was 3.
plot(ns,Boil,type="l",ylim=c(0,1)) #this shows what power each sample size n will give. The first one over 80% was chosen, which was 3.
Boil$power
plot(ns,Boil,type="l",ylim=c(0,1)) #this shows what power each sample size n will give. The first one over 80% was chosen, which was 3.
plot(ns,Boil$power,type="l",ylim=c(0,1)) #this shows what power each sample size n will give. The first one over 80% was chosen, which was 3.
#This histogram is normal, so this assumption is met
# Conduct ANOVA test
model <- lm(data=boilwater, Time~Burner+Pot+Lid+Burner:Pot+Burner:Lid+Lid:Pot) #this fits the data as a linear model
anova(model) #this runs an ANOVA test
1-pf(6.1945,26,2)
1-pf(6.1945,2,26)
5+5
5+3
source('~/.active-rstudio-document')
source('~/.active-rstudio-document', echo=TRUE)
##Libraries
library(tidyverse)
##Libraries
install.packages("tidyverse")
library(tidyverse)
library(vroom)
bike <- vroom("./train.csv")
setwd("~/Braden/Uni/Classes/Semester7/Stat348/Stat348/projects/KaggleBikeShare/KaggleBikeShare")
bike <- vroom("./train.csv")
dplyr::glimpse(dataset)
dplyr::glimpse(bike)
install.packages("skimr")
skimr::skim(bike)
install.packages("DataExplorer")
DataExplorer::plot_intro(dataset)
DataExplorer::plot_intro(bike)
DataExplorer::plot_bar(bike)
DataExplorer::plot_correlation(bike)
DataExplorer::plot_histogram(bike)
install.packages("patchwork")
DataExplorer::plot_correlation(bike)
DataExplorer::plot_histogram(bike)
DataExplorer::plot_bar(bike)
DataExplorer::plot_correlation(bike)
ggplot(data=bike, mapping=aes(x = season, y = count )) +
geom_point() +
geom_smooth(se=FALSE)
ggplot(data=bike, mapping=aes(x = temp, y = count )) +
geom_point() +
geom_smooth(se=FALSE)
DataExplorer::plot_correlation(bike)
ggplot(data=bike, mapping=aes(x = temp, y = atemp )) +
geom_point() +
geom_smooth(se=FALSE)
(plot1 + plot2)/(plot3 + plot4)
plot1 <- DataExplorer::plot_correlation(bike)
plot2 <- DataExplorer::plot_histogram(bike)
plot3 <- DataExplorer::plot_bar(bike)
plot4 <- ggplot(data=bike, mapping=aes(x = temp, y = atemp )) +
geom_point() +
geom_smooth(se=FALSE)+
labs(title="Check for collinearity between temp and atemp")
(plot1 + plot2)/(plot3 + plot4)
plot4 <- ggplot(data=bike, mapping=aes(x = temp, y = count )) +
geom_point() +
geom_smooth(se=FALSE)+
labs(title="Check for relationship between temp and count")
plot4
DataExplorer::plot_correlation(bike)
ggplot(data=bike, mapping=aes(x = windspeed, y = count )) +
geom_point() +
geom_smooth(se=FALSE)+
labs(title="Check for relationship between windspeed and count")
(plot1 + plot2) / (plot3 + plot4)
library(patchwork)
(plot1 + plot2) / (plot3 + plot4)
(plot1 + plot2)/(plot3 + plot4)
plot1 <- DataExplorer::plot_correlation(bike)
plot2 <- DataExplorer::plot_histogram(bike)
plot3 <- DataExplorer::plot_bar(bike)
plot4 <- ggplot(data=bike, mapping=aes(x = windspeed, y = count )) +
geom_point() +
geom_smooth(se=FALSE)+
labs(title="Check for relationship between windspeed and count")
(plot1 + plot2)/(plot3 + plot4)
(plot1 + plot2)/(plot3 + plot4)
plot1/plot3
(plot1+plot2)/plot3
(plot1 + plot2)/(plot3 + plot4)
plot4 <- ggplot(data=bike, mapping=aes(x = windspeed, y = count )) +
geom_point() +
labs(title="Check for relationship between windspeed and count")
(plot1 + plot2)/(plot3+plot4)
ggplot(data=bike, mapping=aes(x = windspeed, y = count )) +
geom_point() +
labs(title="Check for relationship between windspeed and count")
plot4 <- ggplot(data=bike, mapping=aes(x = windspeed, y = count )) +
geom_bar() +
labs(title="Check for relationship between windspeed and count")
ggplot(data=bike, mapping=aes(x = windspeed, y = count )) +
geom_bar() +
labs(title="Check for relationship between windspeed and count")
ggplot(data=bike, mapping=aes(x = windspeed, y = count )) +
geom_bar() +
labs(title="Check for relationship between windspeed and count")
ggplot(data=bike, mapping=aes(x = windspeed, y = count)) +
geom_density() +
labs(title="Check for relationship between windspeed and count")
plot4 <- ggplot(data=bike, mapping=aes(x = windspeed, y = count)) +
geom_point() +
labs(title="Check for relationship between windspeed and count")
ggplot(data=bike, mapping=aes(x = windspeed, y = count)) +
geom_point() +
labs(title="Check for relationship between windspeed and count")
library(patchwork)
(plot1 + plot2)/(plot3+plot4)
(plot3+plot4)
plot3
plot3 <- DataExplorer::plot_bar(bike)
plot3 <- DataExplorer::plot_bar(bike)
plot4 <- ggplot(data=bike, mapping=aes(x = windspeed, y = count)) +
geom_point() +
labs(title="Check for relationship between windspeed and count")
(plot3+plot4)
dplyr::glimpse(bike)
skimr::skim(bike)
plot4 <- ggplot(data=bike, mapping=aes(x = datetime, y = count)) +
geom_point() +
labs(title="Check for relationship between windspeed and count")
plot4
plot3 <- DataExplorer::plot_intro(bike)
(plot1 + plot2)/(plot3+plot4)
plot4 <- ggplot(data=bike, mapping=aes(x = datetime, y = count)) +
geom_point() +
labs(title="Relationship between datetime and count")
(plot1 + plot2)/(plot3+plot4)
##Cleaning Step
##Recatergorize weather "4" value with "3" since there is only one occurrence
biketrain <- biketrain %>%
select(1:9, 12) %>%
mutate(count = log(count))#remove casual and registered
library(tidyverse)
library(vroom)
biketrain <- vroom("./train.csv")
biketest <- vroom("./test.csv")
##Cleaning Step
##Recatergorize weather "4" value with "3" since there is only one occurrence
biketrain <- biketrain %>%
select(1:9, 12) %>%
mutate(count = log(count))#remove casual and registered
library(tidymodels)
my_recipe <- recipe(count ~ ., biketrain)    %>%
#  step_date(datetime, features = "dow") %>% #get day of week
step_time(datetime, features = "hour") %>% #get hour
step_zv(all_predictors()) %>% #remove any predictors with no variance
step_mutate(weather = ifelse(weather == 4, 3, weather), weather = as.factor(weather), season = as.factor(season)) #%>% #turn weather and season into factors
prepped_recipe <- prep(my_recipe)
bake(prepped_recipe, new_data = biketrain)
#################
#Linear Analysis
#################
my_mod <- linear_reg() %>% #Type of model
set_engine("lm") # Engine = What R function to use
bike_workflow <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(my_mod) %>%
fit(data = biketrain) #Fit workflow
extract_fit_engine(bike_workflow) %>% summary()
bikepredictions <- predict(bike_workflow, new_data = biketest)
submission <- bikepredictions %>%
mutate(.pred = ifelse(.pred < 0, 0, .pred)) %>%
mutate(datetime = biketest$datetime) %>%
mutate(datetime=as.character(format(datetime)))  %>%
mutate(count = .pred) %>%
select(2, 3)
vroom_write(submission, "submission.csv", delim = ",")
library(poissonreg)
pois_mod <- poisson_reg() %>% #Type of model
set_engine("glm") # GLM = generalized linear model 45
bike_pois_workflow <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(pois_mod) %>%
fit(data = biketrain) # Fit the workflow
extract_fit_engine(bike_pois_workflow) %>% summary()
bike_predictions <- predict(bike_pois_workflow,
new_data=biketest) # Use fit to predict
submission <- bike_predictions %>%
#mutate(.pred = exp(.pred)) %>%
mutate(datetime = biketest$datetime) %>%
mutate(datetime=as.character(format(datetime)))  %>%
mutate(count = .pred) %>%
select(2, 3)
vroom_write(submission, "submissionpoisson.csv", delim = ",")
submission
library(poissonreg)
pois_mod <- poisson_reg() %>% #Type of model
set_engine("glm") # GLM = generalized linear model 45
bike_pois_workflow <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(pois_mod) %>%
fit(data = biketrain) # Fit the workflow
extract_fit_engine(bike_pois_workflow) %>% summary()
bike_predictions <- predict(bike_pois_workflow,
new_data=biketest) # Use fit to predict
submission <- bike_predictions %>%
#mutate(.pred = exp(.pred)) %>%
mutate(datetime = biketest$datetime) %>%
mutate(datetime=as.character(format(datetime)))  %>%
mutate(count = .pred) %>%
select(2, 3)
submission
submission <- bike_predictions %>%
#mutate(.pred = exp(.pred)) %>%
mutate(datetime = biketest$datetime) %>%
mutate(datetime=as.character(format(datetime)))  %>%
mutate(count = log(.pred)) %>%
select(2, 3)
submission
submission <- bike_predictions %>%
#mutate(.pred = exp(.pred)) %>%
mutate(datetime = biketest$datetime) %>%
mutate(datetime=as.character(format(datetime)))  %>%
mutate(count = exp(.pred)) %>%
select(2, 3)
submission
library(tidymodels)
library(tidymodels)
library(poissonreg)
my_recipe <- recipe(count ~ ., biketrain)    %>%
#  step_date(datetime, features = "dow") %>% #get day of week
step_time(datetime, features = "hour") %>% #get hour
step_zv(all_predictors()) %>% #remove any predictors with no variance
step_mutate(weather = ifelse(weather == 4, 3, weather), weather = as.factor(weather), season = as.factor(season)) %>% #turn weather and season into factors
step_dummy(all_nominal_predictors()) %>%
step_normalize(all_numeric_predictors())
prepped_recipe <- prep(my_recipe)
bake(prepped_recipe, new_data = biketrain)
preg_model <- linear_reg(penalty=1, mixture=0) %>% #Set model and tuning
set_engine("glmnet") # Function to fit in R
preg_wf <- workflow() %>%
add_recipe(myRecipe) %>%
add_model(preg_model) %>%
fit(data=trainingData)
preg_model <- linear_reg(penalty=1, mixture=0) %>% #Set model and tuning
set_engine("glmnet") # Function to fit in R
preg_wf <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(preg_model) %>%
fit(data=trainingData)
preg_model <- linear_reg(penalty=1, mixture=0) %>% #Set model and tuning
set_engine("glmnet") # Function to fit in R
preg_wf <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(preg_model) %>%
fit(data=biketrain)
predict(preg_wf, new_data=biketest)
preg_wf <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(preg_model) %>%
fit(data=biketrain)
install.packages("glmnet")
preg_model <- linear_reg(penalty=1, mixture=0) %>% #Set model and tuning
set_engine("glmnet") # Function to fit in R
preg_wf <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(preg_model) %>%
fit(data=biketrain)
library(tidymodels)
library(poissonreg)
my_recipe <- recipe(count ~ ., biketrain)    %>%
#  step_date(datetime, features = "dow") %>% #get day of week
step_time(datetime, features = "hour") %>% #get hour
step_zv(all_predictors()) %>% #remove any predictors with no variance
step_mutate(weather = ifelse(weather == 4, 3, weather), weather = as.factor(weather), season = as.factor(season)) %>% #turn weather and season into factors
step_dummy(all_nominal_predictors()) %>%
step_normalize(all_numeric_predictors())
prepped_recipe <- prep(my_recipe)
bake(prepped_recipe, new_data = biketrain)
my_recipe <- recipe(count ~ ., biketrain)    %>%
#  step_date(datetime, features = "dow") %>% #get day of week
step_time(datetime, features = "hour") %>% #get hour
step_rm(datetime)%>%
step_zv(all_predictors()) %>% #remove any predictors with no variance
step_mutate(weather = ifelse(weather == 4, 3, weather), weather = as.factor(weather), season = as.factor(season)) %>% #turn weather and season into factors
step_dummy(all_nominal_predictors()) %>%
step_normalize(all_numeric_predictors())
prepped_recipe <- prep(my_recipe)
bake(prepped_recipe, new_data = biketrain)
preg_model <- linear_reg(penalty=1, mixture=0) %>% #Set model and tuning
set_engine("glmnet") # Function to fit in R
preg_wf <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(preg_model) %>%
fit(data=biketrain)
predict(preg_wf, new_data=biketest)
submission <- bike_predictions %>%
mutate(datetime = biketest$datetime) %>%
mutate(datetime=as.character(format(datetime)))  %>%
mutate(count = exp(.pred)) %>% #transform back to original scale
select(2, 3)
submission
vroom_write(submission, "submissionpenalized.csv", delim = ",")
preg_model <- linear_reg(penalty=4, mixture=0) %>% #Set model and tuning
set_engine("glmnet") # Function to fit in R
preg_wf <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(preg_model) %>%
fit(data=biketrain)
predict(preg_wf, new_data=biketest)
submission <- bike_predictions %>%
mutate(datetime = biketest$datetime) %>%
mutate(datetime=as.character(format(datetime)))  %>%
mutate(count = exp(.pred)) %>% #transform back to original scale
select(2, 3)
vroom_write(submission, "submissionpenalized.csv", delim = ",")
preg_model <- linear_reg(penalty=.25, mixture=0) %>% #Set model and tuning
set_engine("glmnet") # Function to fit in R
preg_wf <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(preg_model) %>%
fit(data=biketrain)
predict(preg_wf, new_data=biketest)
submission <- bike_predictions %>%
mutate(datetime = biketest$datetime) %>%
mutate(datetime=as.character(format(datetime)))  %>%
mutate(count = exp(.pred)) %>% #transform back to original scale
select(2, 3)
vroom_write(submission, "submissionpenalized.csv", delim = ",")
preg_model <- linear_reg(penalty=10, mixture=0) %>% #Set model and tuning
set_engine("glmnet") # Function to fit in R
preg_wf <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(preg_model) %>%
fit(data=biketrain)
predict(preg_wf, new_data=biketest)
submission <- bike_predictions %>%
mutate(datetime = biketest$datetime) %>%
mutate(datetime=as.character(format(datetime)))  %>%
mutate(count = exp(.pred)) %>% #transform back to original scale
select(2, 3)
vroom_write(submission, "submissionpenalized.csv", delim = ",")
preg_model <- linear_reg(penalty=1, mixture=1) %>% #Set model and tuning
set_engine("glmnet") # Function to fit in R
preg_wf <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(preg_model) %>%
fit(data=biketrain)
predict(preg_wf, new_data=biketest)
submission <- bike_predictions %>%
mutate(datetime = biketest$datetime) %>%
mutate(datetime=as.character(format(datetime)))  %>%
mutate(count = exp(.pred)) %>% #transform back to original scale
select(2, 3)
submission
vroom_write(submission, "submissionpenalized.csv", delim = ",")
vroom_write(submission, "submissionpenalized.csv", delim = ",")
preg_model <- linear_reg(penalty=.25, mixture=1) %>% #Set model and tuning
set_engine("glmnet") # Function to fit in R
preg_wf <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(preg_model) %>%
fit(data=biketrain)
predict(preg_wf, new_data=biketest)
submission <- bike_predictions %>%
mutate(datetime = biketest$datetime) %>%
mutate(datetime=as.character(format(datetime)))  %>%
mutate(count = exp(.pred)) %>% #transform back to original scale
select(2, 3)
vroom_write(submission, "submissionpenalized.csv", delim = ",")
bike_predictions_pen <- predict(preg_wf, new_data=biketest)
submission <- bike_predictions_pen %>%
mutate(datetime = biketest$datetime) %>%
mutate(datetime=as.character(format(datetime)))  %>%
mutate(count = exp(.pred)) %>% #transform back to original scale
select(2, 3)
vroom_write(submission, "submissionpenalized.csv", delim = ",")
preg_model <- linear_reg(penalty=1, mixture=0) %>% #Set model and tuning
set_engine("glmnet") # Function to fit in R
preg_wf <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(preg_model) %>%
fit(data=biketrain)
bike_predictions_pen <- predict(preg_wf, new_data=biketest)
submission <- bike_predictions_pen %>%
mutate(datetime = biketest$datetime) %>%
mutate(datetime=as.character(format(datetime)))  %>%
mutate(count = exp(.pred)) %>% #transform back to original scale
select(2, 3)
vroom_write(submission, "submissionpenalized.csv", delim = ",")
preg_model <- linear_reg(penalty=1, mixture=1) %>% #Set model and tuning
set_engine("glmnet") # Function to fit in R
preg_wf <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(preg_model) %>%
fit(data=biketrain)
bike_predictions_pen <- predict(preg_wf, new_data=biketest)
submission <- bike_predictions_pen %>%
mutate(datetime = biketest$datetime) %>%
mutate(datetime=as.character(format(datetime)))  %>%
mutate(count = exp(.pred)) %>% #transform back to original scale
select(2, 3)
vroom_write(submission, "submissionpenalized.csv", delim = ",")
preg_model <- linear_reg(penalty=.025, mixture=0) %>% #Set model and tuning
set_engine("glmnet") # Function to fit in R
preg_wf <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(preg_model) %>%
fit(data=biketrain)
bike_predictions_pen <- predict(preg_wf, new_data=biketest)
submission <- bike_predictions_pen %>%
mutate(datetime = biketest$datetime) %>%
mutate(datetime=as.character(format(datetime)))  %>%
mutate(count = exp(.pred)) %>% #transform back to original scale
select(2, 3)
vroom_write(submission, "submissionpenalized.csv", delim = ",")
preg_model <- linear_reg(penalty=0, mixture=0) %>% #Set model and tuning
set_engine("glmnet") # Function to fit in R
preg_wf <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(preg_model) %>%
fit(data=biketrain)
bike_predictions_pen <- predict(preg_wf, new_data=biketest)
submission <- bike_predictions_pen %>%
mutate(datetime = biketest$datetime) %>%
mutate(datetime=as.character(format(datetime)))  %>%
mutate(count = exp(.pred)) %>% #transform back to original scale
select(2, 3)
vroom_write(submission, "submissionpenalized.csv", delim = ",")
preg_model <- linear_reg(penalty=0.05, mixture=0) %>% #Set model and tuning
set_engine("glmnet") # Function to fit in R
preg_wf <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(preg_model) %>%
fit(data=biketrain)
bike_predictions_pen <- predict(preg_wf, new_data=biketest)
submission <- bike_predictions_pen %>%
mutate(datetime = biketest$datetime) %>%
mutate(datetime=as.character(format(datetime)))  %>%
mutate(count = exp(.pred)) %>% #transform back to original scale
select(2, 3)
vroom_write(submission, "submissionpenalized.csv", delim = ",")
preg_model <- linear_reg(penalty=0.5, mixture=0) %>% #Set model and tuning
set_engine("glmnet") # Function to fit in R
preg_wf <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(preg_model) %>%
fit(data=biketrain)
bike_predictions_pen <- predict(preg_wf, new_data=biketest)
submission <- bike_predictions_pen %>%
mutate(datetime = biketest$datetime) %>%
mutate(datetime=as.character(format(datetime)))  %>%
mutate(count = exp(.pred)) %>% #transform back to original scale
select(2, 3)
vroom_write(submission, "submissionpenalized.csv", delim = ",")
preg_model <- linear_reg(penalty=100, mixture=0) %>% #Set model and tuning
set_engine("glmnet") # Function to fit in R
preg_wf <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(preg_model) %>%
fit(data=biketrain)
bike_predictions_pen <- predict(preg_wf, new_data=biketest)
submission <- bike_predictions_pen %>%
mutate(datetime = biketest$datetime) %>%
mutate(datetime=as.character(format(datetime)))  %>%
mutate(count = exp(.pred)) %>% #transform back to original scale
select(2, 3)
vroom_write(submission, "submissionpenalized.csv", delim = ",")
?rbinom
